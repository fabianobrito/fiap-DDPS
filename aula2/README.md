# Script em Python3 para executar a segunda entregua do trabalho de DISTRIBUTED DATA PROCESSING & STORAGE com professor LEANDRO MORAES MENDES 

## EXECUTAR 
## Para executar o script
   precisa subir com o ambiente do hadoop no docker. A configuração e instalação do que é necessário estão nesse [Hadoop Docker](https://github.com/fabiogjardim/bigdata_docker/)<p>
   O trabalho consiste em aplicar os conceitos e comandos da matéria HIVE nas aulas de DDPS.<p>
   O dataset utiliza a ideia de uma empresa de artigos de esportes radicais e acessorios.
   O dataset esta para a atividade está nesse [link](https://drive.google.com/drive/folders/1OfZTSYcgcun-S7UFNVAzbcr0-PzlEc08)
   * esse script é recomendado a ser executado em ambiente linux
   * antes de executar o script certifique-se de em sua máquina os seguintes modulos estejam instalados:
    
     *  ter o pip do pacote python instalado 
     *  sudo apt-get install libsasl2-dev
     *  sudo pip install sasl
     *  sudo pip install thrift_sasl
     *  sudo pip install pyhive
      
   * antes de executar o script certifique-se que o ambiente hadoop no docker esta funcionando e com usuário root da máquina
   * execute o script python estando na raiz do projeto através do comando 'python3 aula2/main.py'
